{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook for making synthetic training data from traffic sign templates\n",
    "Various image processing techniques are applied to the templates to generate synthetic data. Functions are defined to apply various image processing techniques to the templates. The functions are then combined into pipelines which are applied to the templates to generate synthetic data. The synthetic data is then used to train a traffic sign classifier."
   ],
   "id": "3ba6350b6576658d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650a4e85-61b2-446e-8c8b-98196f975dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "import cProfile\n",
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c16f112984ff83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T18:53:56.865699Z",
     "start_time": "2024-04-27T18:53:56.859909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_root = 'data/train_templates'\n",
    "synthetic_root = 'data/synthetic'\n",
    "if not os.path.exists(synthetic_root):\n",
    "    os.makedirs(synthetic_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bdbc58b0310c1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T18:54:53.598647Z",
     "start_time": "2024-04-27T18:54:53.578676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # scale image so width is 1000 pixels and keep aspect ratio\n",
    "    scale = 256 / image.shape[1]\n",
    "    image = cv2.resize(image, (0, 0), fx=scale, fy=scale)\n",
    "    return image"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Rotate and tilt images\n",
    "The `rotate_image` function rotates an image by a random angle within a specified range. The `tilt_image` function tilts an image by a random angle within a specified range. The `apply_accidental_deformations` function applies accidental deformations to an image to simulate real-world scenarios where the image may be deformed due to various reasons such as dirt, scratches, or other factors."
   ],
   "id": "f97745c8f8b2d635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rotate_image(image, min_angle, max_angle, std_dev=6):\n",
    "    std_dev = (max_angle - min_angle) / std_dev\n",
    "    angle = np.clip(np.random.normal((min_angle + max_angle) / 2, std_dev), min_angle, max_angle)\n",
    "    h, w = image.shape[:2]\n",
    "    channels = image.shape[2] if image.ndim == 3 else 1\n",
    "    new_w = int(np.ceil(w * np.abs(np.cos(np.radians(angle))) + h * np.abs(np.sin(np.radians(angle)))))\n",
    "    new_h = int(np.ceil(w * np.abs(np.sin(np.radians(angle))) + h * np.abs(np.cos(np.radians(angle)))))\n",
    "    center = (w // 2, h // 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rot_mat[0, 2] += (new_w - w) / 2\n",
    "    rot_mat[1, 2] += (new_h - h) / 2\n",
    "\n",
    "    if channels != 4:\n",
    "        # If no alpha channel, add one\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    result = cv2.warpAffine(image, rot_mat, (new_w, new_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
    "    return result\n",
    "\n",
    "def tilt_image(image, std_dev, tilt_type='random', padding=75):\n",
    "    h, w = image.shape[:2]\n",
    "    channels = image.shape[2] if image.ndim == 3 else 1\n",
    "    padded_h = h + 2 * padding\n",
    "    padded_w = w + 2 * padding\n",
    "\n",
    "    # Add an alpha channel if it does not exist\n",
    "    if channels != 4:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Create a new padded image with the alpha channel\n",
    "    padded_image = np.zeros((padded_h, padded_w, 4), dtype=np.uint8)\n",
    "\n",
    "    # Copy the input image into the center of the padded image\n",
    "    padded_image[padding:padding + h, padding:padding + w, :] = image\n",
    "\n",
    "    src = np.float32([[padding, padding], [padding + w, padding], [padding, padding + h], [padding + w, padding + h]])\n",
    "\n",
    "    # Randomly determine the tilt type and calculate the angle\n",
    "    # Sample from the normal distribution\n",
    "    tilt_angle_side = np.abs(np.clip(np.random.normal(0, std_dev), -0.5, 0.5))  # std dev adjusted to fit range mostly within -0.5 to 0.5\n",
    "    tilt_angle_front = np.clip(np.random.normal(0.5, std_dev), 0, 1)\n",
    "    if tilt_type == 'random':\n",
    "        tilt_type = np.random.choice(['front', 'right', 'left'])\n",
    "\n",
    "    # Define transformations based on the tilt type\n",
    "    if tilt_type == 'front':\n",
    "        dst = np.float32([\n",
    "            [padding + 0.3 * w * (1 - tilt_angle_front), padding],\n",
    "            [padding + w - 0.3 * w * (1 - tilt_angle_front), padding],\n",
    "            [padding + 0.3 * w * tilt_angle_front, padding + h],\n",
    "            [padding + w - 0.3 * w * tilt_angle_front, padding + h]\n",
    "        ])\n",
    "\n",
    "    elif tilt_type == 'right':\n",
    "        factor = np.sin(np.pi * tilt_angle_side) * 0.5\n",
    "        dst = np.float32([\n",
    "            [padding, padding - factor * h],              # Top-left stays\n",
    "            [padding + w - factor * w, padding],          # Top-right moves left\n",
    "            [padding, padding + h + factor * h],          # Bottom-left stays\n",
    "            [padding + w - factor * w, padding + h]       # Bottom-right moves left\n",
    "        ])\n",
    "    elif tilt_type == 'left':\n",
    "        factor = np.sin(np.pi * tilt_angle_side) * 0.5\n",
    "        dst = np.float32([\n",
    "            [padding + factor * w, padding],\n",
    "            [padding + w, padding - factor * h],\n",
    "            [padding + factor * w, padding + h],\n",
    "            [padding + w, padding + h + factor * h]\n",
    "        ])\n",
    "    else:\n",
    "        dst = src\n",
    "        \n",
    "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    result = cv2.warpPerspective(padded_image, matrix, (padded_w, padded_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
    "\n",
    "    return result"
   ],
   "id": "16cb57b66ed3a6b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Apply accidental deformations\n",
    "The `apply_accidental_deformations` function applies accidental deformations to an image to simulate real-world scenarios where the image may be deformed due to various reasons such as dirt, scratches, or other factors."
   ],
   "id": "1b2218fbeb666b54"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ae8d4fc0e923d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:21:12.849567Z",
     "start_time": "2024-04-27T19:21:12.839979Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_accidental_deformations(image, num_regions=5, size_range=(5, 20), skip_probability=0.6):\n",
    "    \"\"\"\n",
    "    Apply accidental deformations to the image, making deformed regions transparent.\n",
    "\n",
    "    Parameters:\n",
    "        image: Input image to deform. Expected to have an alpha channel.\n",
    "        num_regions: Number of deformation regions to generate.\n",
    "        size_range: Tuple of (min, max) size for the deformation regions.\n",
    "\n",
    "    Returns:\n",
    "        The deformed image.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < skip_probability:\n",
    "        return image\n",
    "    height, width = image.shape[:2]\n",
    "    channels = image.shape[2] if image.ndim == 3 else 1\n",
    "\n",
    "    # Ensure image has an alpha channel\n",
    "    if channels != 4:\n",
    "        deformed_image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    else:\n",
    "        deformed_image = image.copy()\n",
    "\n",
    "    num_regions = np.random.randint(1, num_regions + 1)\n",
    "\n",
    "    for _ in range(num_regions):\n",
    "        # Generate random region\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(size_range[0], size_range[1])\n",
    "\n",
    "        # Create a mask where the region will be transparent\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        cv2.circle(mask, (x, y), size, 1, thickness=-1)\n",
    "\n",
    "        # Set alpha to 0 (fully transparent) in the deformed regions\n",
    "        deformed_image[mask == 1, 3] = 0\n",
    "\n",
    "    return deformed_image\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Add background\n",
    "The `add_background` function adds a random noise background to an image. The function first crops the image to the non-transparent parts and then generates Gaussian noise for the background with random colors. The function then creates a three-channel noise background and applies the noise only where the alpha channel is 0 (transparent areas) and copies the original image data elsewhere."
   ],
   "id": "9f1ca4c18028d5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322ee7e15bf69a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:21:13.733192Z",
     "start_time": "2024-04-27T19:21:13.722754Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_background(image):\n",
    "    # Crop to the non-transparent parts of the image\n",
    "    cropped_image = extract_cropped_image(image)\n",
    "\n",
    "    # Generate Gaussian noise for the background with random colors\n",
    "    h, w = cropped_image.shape[:2]\n",
    "    noise_red = np.random.normal(loc=128, scale=30, size=(h, w)).astype(np.uint8)\n",
    "    noise_green = np.random.normal(loc=128, scale=30, size=(h, w)).astype(np.uint8)\n",
    "    noise_blue = np.random.normal(loc=128, scale=30, size=(h, w)).astype(np.uint8)\n",
    "\n",
    "    # Create a three-channel noise background\n",
    "    noise_background = np.stack((noise_blue, noise_green, noise_red), axis=-1)  # Note the order is BGR for OpenCV\n",
    "\n",
    "    # Create an empty array for the final image with only RGB channels\n",
    "    final_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    # Apply the noise only where the alpha channel is 0 (transparent areas) and copy original image data elsewhere\n",
    "    alpha_channel = cropped_image[:,:,3] / 255.0  # Normalize alpha values to range [0,1] for blending\n",
    "    for i in range(3):  # Process each color channel\n",
    "        final_image[:,:,i] = (alpha_channel * cropped_image[:,:,i] + (1 - alpha_channel) * noise_background[:,:,i]).astype(np.uint8)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "def extract_cropped_image(image):\n",
    "    # Extract the alpha channel\n",
    "    alpha = image[:, :, 3]\n",
    "\n",
    "    # Ensure alpha channel is in the correct format (CV_8UC1)\n",
    "    alpha = alpha.astype(np.uint8)\n",
    "\n",
    "    # Threshold the alpha channel to create a binary mask\n",
    "    _, alpha_binary = cv2.threshold(alpha, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(alpha_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the bounding box coordinates from the contours\n",
    "        x_min, y_min, w, h = cv2.boundingRect(contours[0])\n",
    "        for contour in contours:\n",
    "            x, y, w_i, h_i = cv2.boundingRect(contour)\n",
    "            x_max = max(x_min + w, x + w_i)\n",
    "            y_max = max(y_min + h, y + h_i)\n",
    "            x_min = min(x_min, x)\n",
    "            y_min = min(y_min, y)\n",
    "            w, h = x_max - x_min, y_max - y_min\n",
    "\n",
    "        # Crop the image using the bounding box coordinates\n",
    "        cropped_output = image[y_min:y_min+h, x_min:x_min+w, :]\n",
    "\n",
    "        return cropped_output\n",
    "    else:\n",
    "        # Return an empty image with an alpha channel if no contours are found\n",
    "        return np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7a256418123e98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:21:14.236905Z",
     "start_time": "2024-04-27T19:21:14.231126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert alpha to pink when no background noise is added\n",
    "def convert_alpha_to_pink(image):\n",
    "    \"\"\"\n",
    "    Convert an image with an alpha channel to a 3-channel BGR image,\n",
    "    replacing transparent areas with a pink background.\n",
    "\n",
    "    Parameters:\n",
    "        image: Input image (expected to be BGRA).\n",
    "\n",
    "    Returns:\n",
    "        A BGR image where transparent areas are now pink.\n",
    "    \"\"\"\n",
    "    if image.shape[2] == 4:  # Check if the image has an alpha channel\n",
    "        image = extract_cropped_image(image)\n",
    "        # Create a pink background image\n",
    "        pink_background = np.ones((image.shape[0], image.shape[1], 3), dtype=np.uint8) * np.array([180, 105, 255], dtype=np.uint8)\n",
    "        # Use alpha channel as a mask to combine the image with the pink background\n",
    "        alpha_channel = image[:, :, 3] / 255.0\n",
    "        image_rgb = image[:, :, :3]\n",
    "        foreground = (image_rgb * alpha_channel[:, :, np.newaxis]).astype(np.uint8)\n",
    "        background = (pink_background * (1 - alpha_channel[:, :, np.newaxis])).astype(np.uint8)\n",
    "        return cv2.add(foreground, background)\n",
    "    else:\n",
    "        return image\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Change contrast and brightness\n",
    "The `change_contrast` function changes the contrast of an image by a random factor within a specified range. The `change_brightness` function changes the brightness of an image by a random value within a specified range. The `apply_irregular_illumination` function applies irregular illumination to an image, affecting only non-transparent areas."
   ],
   "id": "c3b196757ef0ddf4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4229eec7b572f7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:21:14.716213Z",
     "start_time": "2024-04-27T19:21:14.710893Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_contrast(image, factor_range=(0.5, 1.5)):\n",
    "    factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "    return cv2.convertScaleAbs(image, alpha=factor, beta=0) #beta = 0, because beta changes brightness, alpha increases/decreases contrast\n",
    "\n",
    "def change_brightness(image, value_range=(-15, 35)):\n",
    "    value = np.random.randint(value_range[0], value_range[1])\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #convert image to the HSV (Hue, Saturation, Value) color space to manipulate value channel which represents brightness\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    if value >= 0:\n",
    "        v = cv2.add(v, value)\n",
    "        v[v > 255] = 255\n",
    "    else:\n",
    "        v = cv2.subtract(v, abs(value))\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    image = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR) #convert back to original color space\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da53774d-95a3-47d3-ac84-20624ad4ca26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_fast_gaussian_blur(illumination_layer, size_range):\n",
    "    \"\"\" Apply Gaussian blur more efficiently using separable convolution. \"\"\"\n",
    "    sigma = size_range[1] / 4  # Adjust sigma to a smaller value for faster computation\n",
    "    kernel_size = int(6 * sigma + 1)  # Kernel size as an odd number close to 6*sigma\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1  # Ensure kernel size is odd\n",
    "\n",
    "    # Apply separable Gaussian blur\n",
    "    blur_x = cv2.GaussianBlur(illumination_layer, (kernel_size, 1), sigmaX=sigma)\n",
    "    blur_final = cv2.GaussianBlur(blur_x, (1, kernel_size), sigmaX=0, sigmaY=sigma)  # Correctly specify sigmaX\n",
    "    return blur_final\n",
    "\n",
    "# Modify the main function to use the new fast Gaussian blur function\n",
    "def apply_irregular_illumination(image, std_dev, intensity_range=(50, 255), size_range=(25, 100), num_spots=20):\n",
    "    height, width = image.shape[:2]\n",
    "    channels = image.shape[2] if image.ndim == 3 else 1\n",
    "\n",
    "    if channels != 4:\n",
    "        raise ValueError(\"Image must have an alpha channel (BGRA)\")\n",
    "\n",
    "    illumination_layer = np.zeros((height, width), dtype=np.uint8)\n",
    "    num_spots = int(np.abs(np.clip(np.random.normal(0, std_dev), -num_spots, num_spots)))\n",
    "    for _ in range(num_spots):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(size_range[0], size_range[1])\n",
    "        intensity = np.random.randint(intensity_range[0], intensity_range[1])\n",
    "        cv2.circle(illumination_layer, (x, y), size, (intensity,), thickness=-1)\n",
    "\n",
    "    # Use optimized Gaussian blur\n",
    "    blurred_illumination = apply_fast_gaussian_blur(illumination_layer, size_range)\n",
    "    blurred_illumination_bgra = cv2.cvtColor(blurred_illumination, cv2.COLOR_GRAY2BGRA)\n",
    "    blurred_illumination_bgra[:, :, 3] = image[:, :, 3]\n",
    "\n",
    "    illuminated_image = cv2.addWeighted(image, 1, blurred_illumination_bgra, 0.5, 0)\n",
    "    return illuminated_image\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Apply random blur\n",
    "The `apply_random_blur` function applies a random blur to an image. The function selects a random blur function from a list of blur functions and applies it to the image. The function applies a blur only 40% of the time. The different blur functions include sharpening, mean blur, median blur, Gaussian blur, and bilateral filter."
   ],
   "id": "1a445719392164e0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee376d45c5736f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:21:15.587564Z",
     "start_time": "2024-04-27T19:21:15.577758Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sharpen_image(image, amount=9):\n",
    "    # amount controls the strength of the sharpening\n",
    "    kernel_sharpening = np.array([\n",
    "        [0, -1, 0],\n",
    "        [-1, 5, -1],\n",
    "        [0, -1, 0]\n",
    "    ])\n",
    "    sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "    return sharpened\n",
    "\n",
    "def mean_blur_image(image, kernel_range=(5,25)):\n",
    "    # kernel should be odd\n",
    "    kernel_size = np.random.randint(kernel_range[0], kernel_range[1])\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    blurred = cv2.blur(image, (kernel_size, kernel_size))\n",
    "    return blurred\n",
    "\n",
    "\n",
    "def median_blur_image(image, kernel_range=(5,25)):\n",
    "    kernel_size = np.random.randint(kernel_range[0], kernel_range[1])\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    blurred = cv2.medianBlur(image, kernel_size)\n",
    "    return blurred\n",
    "\n",
    "def gaussian_blur_image(image, kernel_range=(5,25), sigma_range=(1, 25)):\n",
    "    kernel_size = np.random.randint(kernel_range[0], kernel_range[1])\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    sigma = np.random.uniform(sigma_range[0], sigma_range[1])\n",
    "    blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n",
    "    return blurred\n",
    "\n",
    "def bilateral_filter_image(image, diameter=15, sigmaColor=25, sigmaSpace=25):\n",
    "    filtered = cv2.bilateralFilter(image, diameter, sigmaColor, sigmaSpace)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def insert_speckle_noise(image, variance_range=(0.02, 0.5)):\n",
    "    # from normal distribution\n",
    "    variance = np.random.uniform(variance_range[0], variance_range[1])\n",
    "    row, col, ch = image.shape\n",
    "    gauss = np.random.randn(row, col, ch) * variance\n",
    "    gauss = gauss.reshape(row, col, ch)\n",
    "    noisy = image + image * gauss\n",
    "    return noisy\n",
    "\n",
    "def apply_random_blur(image):\n",
    "    # Define the list of blur functions\n",
    "    blur_functions = [sharpen_image, mean_blur_image, median_blur_image, gaussian_blur_image, bilateral_filter_image]\n",
    "    \n",
    "    # Apply blur only 40% of the time\n",
    "    if np.random.rand() < 0.4:  # There's a 40% chance to apply a blur\n",
    "        blur_function = np.random.choice(blur_functions)\n",
    "        return blur_function(image)\n",
    "    else:\n",
    "        return image  # Return the original image 60% of the time"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pipeline\n",
    "Setting up the pipeline to apply the image processing functions to the templates. The pipeline is then applied to the templates to generate synthetic data."
   ],
   "id": "5fc49e343d1fc39"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6eeceabeb82019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:32:29.992869Z",
     "start_time": "2024-04-27T19:32:29.988367Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_pipeline(image, pipeline):\n",
    "    for func in pipeline:\n",
    "        if func == rotate_image:\n",
    "            image = func(image, -30, 30, 8)\n",
    "        elif func == tilt_image:\n",
    "            image = func(image, 0.1, tilt_type='random')\n",
    "        elif func == apply_irregular_illumination:\n",
    "            image = func(image, 4)\n",
    "        elif func == change_contrast:\n",
    "            image = func(image, (0.3, 1.5))\n",
    "        elif func == change_contrast:\n",
    "            image = func(image, (-15, 35))\n",
    "        else:\n",
    "            image = func(image)\n",
    "    return image"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Not multi-processing, slow\n",
    "Use when testing the functions or limited resources"
   ],
   "id": "32b0709635eaa120"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7142a63c40b5fe2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:32:30.485963Z",
     "start_time": "2024-04-27T19:32:30.478221Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_synthetic_data(train_root, synthetic_root, pipelines, amount=10):\n",
    "    pipeline_id = 5  # Start naming folders from 1\n",
    "\n",
    "    for pipeline in pipelines:\n",
    "        pipeline_folder = os.path.join(synthetic_root, str(pipeline_id))\n",
    "        if not os.path.exists(pipeline_folder):\n",
    "            os.makedirs(pipeline_folder)\n",
    "\n",
    "        # Process each class folder\n",
    "        for root, dirs, files in os.walk(train_root):\n",
    "            files = [f for f in files if not f.endswith('.DS_Store')]\n",
    "            if not files:\n",
    "                continue\n",
    "\n",
    "            class_name = os.path.basename(root)\n",
    "            class_folder = os.path.join(pipeline_folder, class_name)\n",
    "            if not os.path.exists(class_folder):\n",
    "                os.makedirs(class_folder)\n",
    "            \n",
    "            # Calculate the number of augmentations per template to maintain balance\n",
    "            num_templates = len(files)\n",
    "            augmentations_per_template = max(1, amount // num_templates)\n",
    "\n",
    "            # Generate synthetic images\n",
    "            for file in files:\n",
    "                template = load_image(os.path.join(root, file))\n",
    "                \n",
    "                # Apply each pipeline and generate synthetic data\n",
    "                for i in range(augmentations_per_template):\n",
    "                    synthetic = apply_pipeline(template, pipeline)\n",
    "                    synthetic = convert_alpha_to_pink(synthetic)\n",
    "                    synthetic_filename = f'{i}_{file}'\n",
    "                    cv2.imwrite(os.path.join(class_folder, synthetic_filename), synthetic)\n",
    "        print(f'Generated synthetic data for pipeline {pipeline_id}')\n",
    "        pipeline_id += 1  # Increment the folder ID for the next pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bba2318-651e-4200-a689-ff442638d975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_file(args):\n",
    "    root, file, pipeline, pipeline_folder, class_folder, augmentations_per_template = args\n",
    "    template = load_image(os.path.join(root, file))\n",
    "    for i in range(augmentations_per_template):\n",
    "        synthetic = apply_pipeline(template, pipeline)\n",
    "        synthetic = convert_alpha_to_pink(synthetic)\n",
    "        synthetic_filename = f'{i}_{file}'\n",
    "        cv2.imwrite(os.path.join(class_folder, synthetic_filename), synthetic)\n",
    "\n",
    "def generate_synthetic_data(train_root, synthetic_root, pipelines, amount=50):\n",
    "    pipeline_id = 1  # Start naming folders from 1\n",
    "\n",
    "    for pipeline in tqdm(pipelines):\n",
    "        pipeline_folder = os.path.join(synthetic_root, str(pipeline_id))\n",
    "        if not os.path.exists(pipeline_folder):\n",
    "            os.makedirs(pipeline_folder)\n",
    "\n",
    "        args_list = []\n",
    "        # Process each class folder\n",
    "        for root, dirs, files in os.walk(train_root):\n",
    "            files = [f for f in files if not f.endswith('.DS_Store')]\n",
    "            if not files:\n",
    "                continue\n",
    "\n",
    "            class_name = os.path.basename(root)\n",
    "            class_folder = os.path.join(pipeline_folder, class_name)\n",
    "            if not os.path.exists(class_folder):\n",
    "                os.makedirs(class_folder)\n",
    "\n",
    "            # Calculate the number of augmentations per template to maintain balance\n",
    "            num_templates = len(files)\n",
    "            augmentations_per_template = max(1, amount // num_templates)\n",
    "\n",
    "            # Collect arguments for multiprocessing\n",
    "            for file in files:\n",
    "                args = (root, file, pipeline, pipeline_folder, class_folder, augmentations_per_template)\n",
    "                args_list.append(args)\n",
    "\n",
    "        # Use multiprocessing to process files\n",
    "        with Pool() as pool:\n",
    "            pool.map(process_file, args_list)\n",
    "\n",
    "        print(f'Generated synthetic data for pipeline {pipeline_id}')\n",
    "        pipeline_id += 1  # Increment the folder ID for the next pipeline\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pipelines with different combinations of image processing functions",
   "id": "eeb6db9c574f8512"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f563fda1210ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:32:31.305829Z",
     "start_time": "2024-04-27T19:32:31.301752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    [rotate_image, apply_clahe],\n",
    "    [rotate_image, tilt_image, apply_clahe],\n",
    "    [rotate_image, tilt_image, apply_clahe, add_background],\n",
    "    [rotate_image, tilt_image, apply_clahe, apply_accidental_deformations, add_background],\n",
    "    [rotate_image, tilt_image, apply_clahe, apply_accidental_deformations, apply_irregular_illumination, add_background],\n",
    "    [rotate_image, tilt_image, apply_clahe, apply_accidental_deformations, apply_irregular_illumination, add_background, change_brightness],\n",
    "    [rotate_image, tilt_image, apply_clahe, apply_accidental_deformations, apply_irregular_illumination, add_background, change_brightness, change_contrast],\n",
    "    [rotate_image, tilt_image, apply_clahe, apply_accidental_deformations, apply_irregular_illumination, add_background, change_brightness, change_contrast, apply_random_blur],    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926ddab4a68ef562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:33:54.795752Z",
     "start_time": "2024-04-27T19:32:31.978754Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [02:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgenerate_synthetic_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msynthetic_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipelines\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1500\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 45\u001B[0m, in \u001B[0;36mgenerate_synthetic_data\u001B[0;34m(train_root, synthetic_root, pipelines, amount)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Use multiprocessing to process files\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Pool() \u001B[38;5;28;01mas\u001B[39;00m pool:\n\u001B[0;32m---> 45\u001B[0m     \u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGenerated synthetic data for pipeline \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpipeline_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     48\u001B[0m pipeline_id \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:367\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    363\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:768\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 768\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m    770\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "generate_synthetic_data(train_root, synthetic_root, pipelines, 1500)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Multi-processing, speedy\n",
    "Use when generating a large amount of synthetic data."
   ],
   "id": "9dfa917491244493"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3f331-7d75-40fd-a93f-1e3a5d4e29b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [08:33<59:51, 513.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [26:52<1:25:46, 857.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [46:05<1:22:42, 992.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [1:05:19<1:10:25, 1056.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [1:38:16<1:09:25, 1388.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [2:12:12<53:37, 1608.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [3:19:27<00:00, 1495.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache = {}  # Dictionary to store final results of each pipeline for reuse\n",
    "\n",
    "def apply_pipeline(image, pipeline):\n",
    "    for func in pipeline:\n",
    "        if func == rotate_image:\n",
    "            image = func(image, -30, 30, 8)\n",
    "        elif func == tilt_image:\n",
    "            image = func(image, 0.1, tilt_type='random')\n",
    "        elif func == apply_irregular_illumination:\n",
    "            image = func(image, 4)\n",
    "        elif func == change_contrast:\n",
    "            image = func(image, (0.3, 1.5))\n",
    "        else:\n",
    "            image = func(image)\n",
    "    return image\n",
    "\n",
    "def process_file(args):\n",
    "    root, file, pipeline, pipeline_folder, class_folder, augmentations_per_template = args\n",
    "    template = load_image(os.path.join(root, file))\n",
    "    \n",
    "    # Check for a cached version from a previous pipeline\n",
    "    cache_key = f\"{root}_{file}_{len(pipeline)}\"\n",
    "    if cache_key in cache:\n",
    "        base_image = cache[cache_key]\n",
    "    else:\n",
    "        base_image = template\n",
    "    \n",
    "    for i in range(augmentations_per_template):\n",
    "        synthetic = apply_pipeline(base_image.copy(), pipeline)\n",
    "        synthetic = convert_alpha_to_pink(synthetic)\n",
    "        synthetic_filename = f'{i}_{file}'\n",
    "        cv2.imwrite(os.path.join(class_folder, synthetic_filename), synthetic)\n",
    "    \n",
    "    # Cache the last modified image for this file at this pipeline stage\n",
    "    cache[cache_key] = synthetic\n",
    "\n",
    "def generate_synthetic_data(train_root, synthetic_root, pipelines, amount=50):\n",
    "    pipeline_id = 1  # Start naming folders from 1\n",
    "\n",
    "    for pipeline in tqdm(pipelines):\n",
    "        pipeline_folder = os.path.join(synthetic_root, str(pipeline_id))\n",
    "        if not os.path.exists(pipeline_folder):\n",
    "            os.makedirs(pipeline_folder)\n",
    "\n",
    "        args_list = []\n",
    "        for root, dirs, files in os.walk(train_root):\n",
    "            files = [f for f in files if not f.endswith('.DS_Store')]\n",
    "            if not files:\n",
    "                continue\n",
    "\n",
    "            class_name = os.path.basename(root)\n",
    "            class_folder = os.path.join(pipeline_folder, class_name)\n",
    "            if not os.path.exists(class_folder):\n",
    "                os.makedirs(class_folder)\n",
    "\n",
    "            num_templates = len(files)\n",
    "            augmentations_per_template = max(1, amount // num_templates)\n",
    "\n",
    "            for file in files:\n",
    "                args = (root, file, pipeline, pipeline_folder, class_folder, augmentations_per_template)\n",
    "                args_list.append(args)\n",
    "\n",
    "        with Pool() as pool:\n",
    "            pool.map(process_file, args_list)\n",
    "\n",
    "        print(f'Generated synthetic data for pipeline {pipeline_id}')\n",
    "        pipeline_id += 1\n",
    "\n",
    "# Example use\n",
    "generate_synthetic_data(train_root, synthetic_root, pipelines, 1500)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Profiling the function, for testing purposes\n",
    "Some functions were very slow, so we profiled the function to identify bottlenecks and optimize the code."
   ],
   "id": "468e1f7f11661675"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bd0f3f1-5108-4d7d-864f-15706f8e95fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 1\n",
      "         6302 function calls (6206 primitive calls) in 3.347 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      275    3.192    0.012    3.192    0.012 {method 'acquire' of '_thread.lock' objects}\n",
      "       16    0.092    0.006    0.092    0.006 {built-in method posix.fork}\n",
      "      154    0.021    0.000    0.021    0.000 {built-in method posix.waitpid}\n",
      "       79    0.003    0.000    0.003    0.000 /opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py:621(send)\n",
      "       16    0.003    0.000    0.098    0.006 /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:62(_launch)\n",
      "        7    0.003    0.000    0.003    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       16    0.002    0.000    0.144    0.009 /opt/conda/lib/python3.10/multiprocessing/process.py:110(start)\n",
      "       16    0.002    0.000    0.003    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:80(__init__)\n",
      "       37    0.002    0.000    0.043    0.001 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:592(flush)\n",
      "       17    0.002    0.000    0.002    0.000 /opt/conda/lib/python3.10/multiprocessing/util.py:186(__init__)\n",
      "       16    0.002    0.000    0.140    0.009 /opt/conda/lib/python3.10/multiprocessing/context.py:278(_Popen)\n",
      "        1    0.002    0.002    0.150    0.150 /opt/conda/lib/python3.10/multiprocessing/pool.py:314(_repopulate_pool_static)\n",
      "       79    0.001    0.000    0.005    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:259(schedule)\n",
      "       70    0.001    0.000    0.001    0.000 {built-in method posix.close}\n",
      "       16    0.001    0.000    0.039    0.002 /opt/conda/lib/python3.10/multiprocessing/util.py:433(_flush_std_streams)\n",
      "       16    0.001    0.000    0.138    0.009 /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:15(__init__)\n",
      "       16    0.001    0.000    0.002    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:61(_cleanup)\n",
      "      118    0.001    0.000    0.001    0.000 /opt/conda/lib/python3.10/threading.py:1169(is_alive)\n",
      "       41    0.001    0.000    0.001    0.000 /opt/conda/lib/python3.10/threading.py:545(__init__)\n",
      "       16    0.001    0.000    0.004    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:179(Process)\n",
      "       16    0.001    0.000    0.001    0.000 /opt/conda/lib/python3.10/logging/__init__.py:228(_releaseLock)\n",
      "       41    0.001    0.000    0.001    0.000 /opt/conda/lib/python3.10/threading.py:236(__init__)\n",
      "      236    0.001    0.000    0.001    0.000 {built-in method builtins.next}\n",
      "   145/49    0.001    0.000    0.002    0.000 /opt/conda/lib/python3.10/os.py:345(_walk)\n",
      "       39    0.000    0.000    3.193    0.082 /opt/conda/lib/python3.10/threading.py:288(wait)\n",
      "       41    0.000    0.000    3.193    0.078 /opt/conda/lib/python3.10/threading.py:589(wait)\n",
      "      154    0.000    0.000    0.021    0.000 /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:24(poll)\n",
      "        1    0.000    0.000    3.346    3.346 /tmp/ipykernel_1/1059133975.py:43(generate_synthetic_data)\n",
      "       20    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/_weakrefset.py:86(add)\n",
      "        6    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/multiprocessing/synchronize.py:50(__init__)\n",
      "        1    0.000    0.000    0.154    0.154 /opt/conda/lib/python3.10/multiprocessing/pool.py:183(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "      121    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1102(_wait_for_tstate_lock)\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method posix.scandir}\n",
      "       26    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "        1    0.000    0.000    3.347    3.347 /tmp/ipykernel_1/1409520196.py:2(profile_function)\n",
      "       38    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       93    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/posixpath.py:71(join)\n",
      "       35    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "       79    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:138(_event_pipe)\n",
      "       32    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:94(<genexpr>)\n",
      "       19    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       74    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1145(ident)\n",
      "       46    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "        3    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/threading.py:827(__init__)\n",
      "      118    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "       47    0.000    0.000    0.000    0.000 {built-in method posix.lstat}\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:464(format_meter)\n",
      "       46    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1430(current_thread)\n",
      "       80    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "      253    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       97    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        7    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:655(write)\n",
      "      129    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:553(is_set)\n",
      "        1    0.000    0.000    0.023    0.023 /opt/conda/lib/python3.10/multiprocessing/pool.py:680(_terminate_pool)\n",
      "       17    0.000    0.000    0.024    0.001 /opt/conda/lib/python3.10/multiprocessing/util.py:205(__call__)\n",
      "      130    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:375(<genexpr>)\n",
      "       39    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:276(_acquire_restore)\n",
      "       68    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:99(_check_closed)\n",
      "       32    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:189(name)\n",
      "       47    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/posixpath.py:164(islink)\n",
      "       22    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       48    0.000    0.000    0.000    0.000 /tmp/ipykernel_1/1059133975.py:53(<listcomp>)\n",
      "       45    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/posixpath.py:140(basename)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:471(_map_async)\n",
      "        3    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py:763(init_closure)\n",
      "       46    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/genericpath.py:16(exists)\n",
      "      138    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/posixpath.py:41(_get_sep)\n",
      "       41    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:267(__exit__)\n",
      "        1    0.000    0.000    0.002    0.002 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1198(update)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method posix.kill}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "       41    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:264(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/reduction.py:38(__init__)\n",
      "      188    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        3    0.000    0.000    0.002    0.001 /opt/conda/lib/python3.10/threading.py:916(start)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:153(is_alive)\n",
      "       39    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:273(_release_save)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:56(terminate)\n",
      "        1    0.000    0.000    0.154    0.154 /opt/conda/lib/python3.10/multiprocessing/context.py:115(Pool)\n",
      "      169    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:279(_get_sentinels)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:782(_newname)\n",
      "        1    0.000    0.000    0.003    0.003 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:952(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1301(_make_invoke_excepthook)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:686(_decr_instances)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1446(format_dict)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:273(_is_ascii)\n",
      "       16    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/multiprocessing/util.py:461(close_fds)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:193(name)\n",
      "       39    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:279(_is_owned)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/random.py:519(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/reduction.py:48(dumps)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:224(exitcode)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:333(_screen_shape_linux)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.write}\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:102(acquire)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/tempfile.py:153(__next__)\n",
      "        5    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:400(format_interval)\n",
      "      127    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "        6    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/multiprocessing/context.py:65(Lock)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1150(__str__)\n",
      "        7    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:505(parent_header)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:747(__init__)\n",
      "       33    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/util.py:48(debug)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:128(terminate)\n",
      "        7    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:231(__call__)\n",
      "        2    0.000    0.000    0.003    0.001 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1160(__iter__)\n",
      "      142    0.000    0.000    0.000    0.000 {method 'is_dir' of 'posix.DirEntry' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.cpu_count}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.150    0.150 /opt/conda/lib/python3.10/multiprocessing/pool.py:305(_repopulate_pool)\n",
      "        2    0.000    0.000    0.003    0.001 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1325(refresh)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/queues.py:369(put)\n",
      "       93    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       19    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:39(_remove)\n",
      "        1    0.000    0.000    0.023    0.023 /opt/conda/lib/python3.10/multiprocessing/pool.py:654(terminate)\n",
      "        3    0.000    0.000    0.004    0.001 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1464(display)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:796(__init__)\n",
      "      139    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/weakref.py:165(__setitem__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:213(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/random.py:506(choices)\n",
      "       26    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:46(_send_signal)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/logging/__init__.py:219(_acquireLock)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/weakref.py:353(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/multiprocessing/context.py:110(SimpleQueue)\n",
      "       49    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        1    0.000    0.000    0.003    0.003 /opt/conda/lib/python3.10/multiprocessing/pool.py:671(_help_stuff_finish)\n",
      "        7    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:577(_schedule_flush)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/synchronize.py:114(_make_name)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/weakref.py:106(remove)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:106(release)\n",
      "       79    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.020    0.010 /opt/conda/lib/python3.10/multiprocessing/process.py:142(join)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:181(send_bytes)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/util.py:171(register_after_fork)\n",
      "        8    0.000    0.000    0.003    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:194(inner)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:374(_text_width)\n",
      "        3    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/multiprocessing/queues.py:339(__init__)\n",
      "        3    0.000    0.000    0.003    0.001 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:457(print_status)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:186(__format__)\n",
      "        2    0.000    0.000    0.001    0.001 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1265(close)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:516(Pipe)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'put' of '_queue.SimpleQueue' objects}\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:153(__init__)\n",
      "       41    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:663(__new__)\n",
      "       45    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:187(disable_on_exception)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:390(_send_bytes)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1198(daemon)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1028(_stop)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:205(daemon)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:63(__iter__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:378(disp_len)\n",
      "        1    0.000    0.000    0.002    0.002 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:438(status_printer)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/synchronize.py:97(__exit__)\n",
      "       22    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "        3    0.000    0.000    0.003    0.001 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:451(fp_write)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:117(__init__)\n",
      "       35    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "       47    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
      "       63    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       48    0.000    0.000    0.000    0.000 {method '__exit__' of 'posix.ScandirIterator' objects}\n",
      "       42    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.019    0.010 /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:36(wait)\n",
      "       10    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:53(_commit_removals)\n",
      "       41    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "       48    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method math.floor}\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1064(join)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:27(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:734(__enter__)\n",
      "        6    0.000    0.000    0.001    0.000 /opt/conda/lib/python3.10/multiprocessing/synchronize.py:161(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/tempfile.py:142(rng)\n",
      "        7    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:550(_is_master_process)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:111(remove)\n",
      "        1    0.000    0.000    3.159    3.159 /opt/conda/lib/python3.10/multiprocessing/pool.py:362(map)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:130(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:679(_get_free_pos)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/weakref.py:348(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:365(_send)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       17    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/util.py:44(sub_debug)\n",
      "        1    0.000    0.000    0.001    0.001 /opt/conda/lib/python3.10/multiprocessing/pool.py:345(_setup_queues)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/synchronize.py:94(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1286(fp_write)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/synchronize.py:90(_make_methods)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/functools.py:393(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/os.py:282(walk)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:21(__enter__)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method posix.waitstatus_to_exitcode}\n",
      "        1    0.000    0.000    3.158    3.158 /opt/conda/lib/python3.10/multiprocessing/pool.py:767(get)\n",
      "        4    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:110(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:125(__eq__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:108(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:347(<listcomp>)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/os.py:675(__getitem__)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:360(_close)\n",
      "        1    0.000    0.000    0.023    0.023 /opt/conda/lib/python3.10/multiprocessing/pool.py:738(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:234(ident)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x557391f135e0}\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/threading.py:1183(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:266(_supports_unicode)\n",
      "        9    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/context.py:187(get_context)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/os.py:755(encode)\n",
      "        4    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:113(__exit__)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:152(wrapper_setattr)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/_weakrefset.py:17(__init__)\n",
      "        1    0.000    0.000    3.158    3.158 /opt/conda/lib/python3.10/multiprocessing/pool.py:764(wait)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:226(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1157(__hash__)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:157(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:112(__format__)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/context.py:197(get_start_method)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:167(colour)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:134(_check_closed)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:756(ready)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:760(get_lock)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1153(_comparable)\n",
      "        6    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/process.py:37(current_process)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/dateutil/tz/tz.py:218(utcoffset)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:139(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:351(_check_running)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:156(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/pool.py:266(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:682(<setcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/connection.py:142(_check_writable)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/_monitor.py:94(report)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1147(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:222(__eq__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:163(colour)\n",
      "        3    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:282(_screen_shape_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/multiprocessing/context.py:237(get_context)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:364(fileno)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/utils.py:252(_is_utf)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/dateutil/tz/tz.py:262(_isdst)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/conda/lib/python3.10/site-packages/tqdm/std.py:1301(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.audit}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data for pipeline 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def profile_function():\n",
    "    generate_synthetic_data(train_root, synthetic_root, pipelines, 5)\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.runcall(profile_function)\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.sort_stats('time')  \n",
    "stats.print_stats()\n",
    "\n",
    "\n",
    "profile_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (Local)",
   "language": "python",
   "name": "pytorch-2-0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
